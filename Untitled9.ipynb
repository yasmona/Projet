{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elementary-decrease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Input,ConvLSTM2D,Reshape,Activation,Lambda,Softmax\n",
    "from keras.layers import Dense, LSTM, Input, Embedding, TimeDistributed, Flatten, Dropout,RepeatVector,Reshape,Activation,Lambda,Softmax\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import keras.backend as kerback\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import one_hot\n",
    "import tensorflow \n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "banner-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(f):\n",
    "    data = pd.read_csv(f, sep=\"\\n\",header=None)\n",
    "    list_listword=[]#liste des listes des mots de chaque tweet\n",
    "    list_tweets=data[0].values.tolist()#liste des tweets\n",
    "    l=[]\n",
    "    for text in list_tweets:\n",
    "        text = re.sub(r'http\\S+', '', text)   # Remove URLs\n",
    "        text = re.sub(r'—', ' ', text) \n",
    "        text = re.sub(r'@[a-zA-Z0-9_]+', '', text)  # Remove @ mentions\n",
    "        text = text.strip(\" \")   # Remove whitespace resulting from above\n",
    "        text = re.sub(r' +', ' ', text)   # Remove redundant spaces\n",
    "        l.append(text)\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interesting-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['During our time in the White House, Michelle and I were proud to display artwork from artists like Alma Thomas and Charles Alston whose work provoked thought, challenged our assumptions, and shaped how we define our narrative as a country.', \"There is a lot of disinformation out there, but here’s the truth: You should get a COVID vaccine as soon as it's available to you. It could save your life or a loved one’s.\", 'Climate change is a real threat to us all but feeling helpless or overwhelmed isn’t going to solve it. As long as we stay hopeful and keep working with the urgency the challenge demands, we can make a difference.', 'I’m proud to announce that the Obama Presidential Center will officially break ground in 2021. Our hope is that the center will breathe new life into historic Jackson Park while delivering jobs, growth, and much more to the South Side. Let’s get to work.', 'Black-owned independent bookstores play a critical role in communities all across our country. I wanted to show my support, so I dropped in to surprise the folks from & the Very Smart Brothas Book Club. Take a look.', \"When Jackie Robinson faced down slurs, spiked cleats, and pitches aimed at his head and stole home anyway he didn't only change baseball. He changed the world and paved the way for others, including me. On his birthday, we’re called not only to honor that legacy but build on it.\", 'In her extraordinary career, Cicely Tyson was one of the rare award-winning actors whose work on the screen was surpassed only by what she was able to accomplish off of it. She had a heart unlike any other and for 96 years, she left a mark on the world that few will ever match.', 'Hank Aaron was one of the best baseball players we’ve ever seen and one of the strongest people I’ve ever met. Michelle and I send our thoughts and prayers to the Aaron family and everyone who was inspired by this unassuming man and his towering example.', 'This is a time for boldness and President Biden is already delivering. By rejoining the Paris climate accords on day one, he declared loudly and clearly that the U.S. will once again lead the fight against climate change. And this is only the beginning.', 'Today was a good day. And it was only possible because of you. Because you made calls. Because you marched. Because you wore your masks and voted like never before. For four years, you defended our democracy with everything you had and now, our country can enter a new day.', 'Congratulations to my friend, President ! This is your time.', 'If anyone had a right to question whether our democracy was worth redeeming, it was Dr. Martin Luther King, Jr. Because in the face of billy clubs and lynchings, poll taxes and literacy tests, he never gave in to violence, never waved a traitorous flag or gave up on our country.', 'Happy birthday to my love, my partner, and my best friend. Every moment with you is a blessing. Love you, Miche.', 'My friend John Lewis is surely smiling down on his beloved Georgia this morning, as people across the state carried forward the baton that he and so many others passed down to them.', \"Georgia voters If you're in line before the polls close at 7 pm, stay there. You have the right to vote, no matter how long it takes. If you have questions, call the Georgia voter protection hotline at 1-888-730-5816. Let's bring this home.\", 'Georgia, this is it. Today is Election Day and your vote can help elect and Jon to the U.S. Senate. Make your voice heard today and vote either in person or by dropping off your mail-in ballot at a ballot drop box.', 'If you have questions or run into any issues at your polling location, call the Georgia voter protection hotline at 1-888-730-5816.', 'Tomorrow is Election Day in Georgia and the stakes could not be higher. We’re seeing how far some will go to retain power and threaten the fundamental principles of our democracy. But our democracy isn’t about any individual, even a president it’s about you.', 'If you’re a Georgia voter, you can respond tomorrow with the most powerful tool we have as Americans your vote. Make a plan to vote in person or drop off your mail-in-ballot at a ballot drop box. Check-in with your family and friends to do the same.', \"After a year that has tested us in unimaginable ways, we've seen how people from all walks of life have stepped up to create change to make things better. Here's to ringing in 2021 with optimism for what's to come and a belief that our best days are still ahead. Happy New Year!\", 'We’re just one week away from the U.S. Senate runoff elections in Georgia. If you’re in Georgia, make a plan to vote early if you can and reach out to your friends and family to make sure they do the same.', \"The redistricting process in 2021 will be a snapshot of democracy in action, and is working to ensure everyone has a voice. We’ve accomplished a lot together this year, but there's still so much work to do.\", 'This Christmas looks different for all of us. As we spend time with those we love in person or virtually let us celebrate the blessings we cherish, embrace the spirit of giving, and look out for one another. From my family to yours, Merry Christmas!', 'It’s unconscionable that there are families worried over the holidays that they’ll be evicted next month. Extending the eviction moratorium was a start, but Congress has to do more to help folks who can’t pay rent because of COVID-related unemployment.', 'With COVID cases surging worse than ever, getting vaccinated is one of the most important things we can do. But until the vaccine is widely available, socially distancing and wearing masks will actually save even more lives, and alleviate the pressure on healthcare workers.', 'Like everyone else, we were stuck inside a lot this year, and with streaming further blurring the lines between theatrical movies and television features, I’ve expanded the list to include visual storytelling that I’ve enjoyed this year, regardless of format.', \"Happy Hanukkah to all those celebrating around the world. This year has tested us all, but it's also clarified what really matters. May the lights of the menorah remind us to cherish the blessings we have and offer glimmers of hope. From my family to yours, Chag Sameach!\", 'In A Promised Land, I talk about the decisions I had to make during the first few years of my presidency.', \"With COVID-19 cases reaching an all-time high this week, we've got to continue to do our part to protect one another. This pandemic is far from over and your actions can help save lives.\", 'To all of you in Georgia, today is the last day to register to vote in the upcoming runoff election. Take a few minutes right now to register to vote, and then make sure everybody you know is registered, too.', 'Let’s all do our part this Thanksgiving to keep people safe and healthy. Celebrate virtually, if you can. Wear a mask. And as always, listen to the experts. The choices you make could save lives.', 'Michelle and I are eager to bring the Obama Presidential Center to our hometown a way to honor the city we love, all those who came before us, and pay tribute to people coming together to do extraordinary things.', 'This was fun. I heard Tim and Fred were listening to some of the songs on my A Promised Land playlist, so I decided to drop in and surprise them. We talked about a lot, from Bob Dylan to old-school mixtapes to the role music played in my memoir.', 'My memoir, A Promised Land, is out today. I hope you’ll read it. My goal was to give you some insight into the events and people that shaped me during the early years of my presidency. Most of all, I hope it inspires you to see yourself playing a role in shaping a better world.', 'More than anyone else, I wrote my book for young people as an invitation to once again remake the world, and to bring about, through hard work, determination, and a big dose of imagination, an America that finally aligns with all that is best in us.', 'Today, we’re reminded of our solemn obligation: to serve our veterans as well as they have served us. To all of our veterans and service members, we’re forever grateful for your commitment to our country and your willingness to put it all on the line for us. Thank you.', \"There's a reason some folks are trying to make it hard for you to vote: They know that if you do, things change. And that's why the answer isn't to stay at home. It's to turn out like never before and show them what this country stands for.\", 'For eight years, Joe was the last one in the room whenever I faced a big decision. He made me a better president. And today, we have the chance to elect Joe and Kamala to build our country back better. But it’s going to take every single one of us.', 'More than 100 million Americans have already cast a ballot in this election. Joel, Monica, and Andrés are three of them and I got to FaceTime with them before they voted. Join them and get out there and vote today.', 'Our administration literally left this White House a playbook that would have shown them how to respond before COVID-19 reached our shores. Joe and I revisited it recently. Take a look and then vote for a leader who will get this virus under control.', 'We can’t afford to be complacent. Not this time. Not in this election. Make a plan right now.', 'You could be the difference between someone making it out to the polls or staying home. And many states could be decided by a handful of votes. Join me and make some calls for Joe in the last few days of this election.', 'What we do in these next four days will not just decide the next four years, but the future of this country. Let’s choose hope over fear. I’m counting on you.', 'An important reminder as millions of folks across the country vote early or make plans to vote on November 3: You have the right to vote. If you run into any issues at your polling place, call 1-866-687-8683 or your voter protection hotline.', \"Here are some helpful tips about voting in person this year. Do vote early if you can, don't get out of line, and a couple of other important reminders. If you're voting by mail, now is the time to drop off your ballot at a drop box or an election office.\", \"We’ve only got one week left in this election. I’m in Orlando for Joe Biden to get more folks to vote and use their voices to determine the direction of our country. Let's go.\", 'Republicans love to say right before an election that they’ll protect preexisting conditions. Well, Joe and I actually did it and he’ll keep protecting your health care as president. We’ve got eight days left. Vote.', 'From police reform to funding our schools, the officials with the most power to change the issues we care about in our communities are often found at the state and local levels. So educate yourselves up and down the ticket, make a plan to vote, and vote.', 'Nobody should have to wait 11 hours to vote, but we’re all grateful that you and all those in line with you stuck it out. Keep making your voices heard, everybody. Our democracy depends on it.', \"There's a lot at stake in this election. From getting this pandemic under control to building a fairer economy to taking on climate change and protecting our health care, your vote can make all the difference. Register today and make a plan to vote early.\", 'And congratulations to my friend Alex Smith, for fighting back from a life-threatening injury to start at quarterback again for the Washington Football Team. It’s a testament to his strength, determination and the love and support of his family.', 'Right in the middle of a pandemic it failed to control, this administration is trying to get the Supreme Court to eliminate preexisting conditions protections for more than 100 million Americans.', 'Michelle and I hope that the President, First Lady, and all those affected by the coronavirus around the country are getting the care they need and are on the path to a speedy recovery.', 'Obviously, we’re in the midst of a big political battle right now, and while there’s a lot at stake, let’s remember that we’re all Americans. We’re all human beings. And we want everyone to be healthy, no matter our party.', 'I’m proud to endorse these outstanding Democratic candidates who will work to get the virus under control, rebuild the economy and the middle class, and protect Americans’ health care and preexisting conditions protections. Support these candidates––and vote early if you can.', \"All right, let's try something new. If you’re in the United States, send me a text at 773-365-9687 I want to hear how you're doing, what's on your mind, and how you're planning on voting this year. I'll be in touch from time to time to share what's on my mind, too.\", \"If you're looking for a way to get involved in this upcoming election, sign up to volunteer as a poll worker for early voting and Election Day. You can help your community and make sure this election runs fairly and safely.\", 'There’s no feeling like finishing a book, and I’m proud of this one. In A Promised Land, I try to provide an honest accounting of my presidency, the forces we grapple with as a nation, and how we can heal our divisions and make democracy work for everybody.', \"Over the last few months, I've learned a thing or two from the young people in our country. I figured I would return the favor by sharing with you how to make a plan to vote in this upcoming election.\", 'The fires across the West Coast are just the latest examples of the very real ways our changing climate is changing our communities. Protecting our planet is on the ballot. Vote like your life depends on it because it does.', \"This Labor Day, let’s thank all those who've kept our country going this year nurses, teachers, delivery drivers, food service workers, and many more. We can honor them by building our system back even better so that essential workers are treated like it, pandemic or not.\", \"It might be Labor Day weekend, but let’s all remember that we're still in the middle of a pandemic. Wear a mask, practice social distancing, and follow the experts. It’ll save lives.\", 'Completing the Census is crucial because it will shape our communities for the next decade. Everything from critical funds and resources for health care, infrastructure, and education to political representation.', 'Joe and Kamala have what it takes to lead this country out of these dark times and build it back better. Join me in helping them get elected.', 'If you can volunteer as a poll worker for early voting and Election Day, I hope you’ll do it. You can help make sure this election runs fairly and safely and that’s one of the most crucial things any of us can do for our country right now.', 'Chadwick came to the White House to work with kids when he was playing Jackie Robinson. You could tell right away that he was blessed. To be young, gifted, and Black; to use that power to give them heroes to look up to; to do it all while in pain – what a use of his years.']\n"
     ]
    }
   ],
   "source": [
    "list_tweets=prepare_data('C:/tweet.txt')\n",
    "print(list_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "better-preserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "def tokenizer_data(list_tweets):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(list_tweets)\n",
    "    sequences = tokenizer.texts_to_sequences(list_tweets)\n",
    "    vocab_size=len(tokenizer.word_index)\n",
    "    return sequences, tokenizer\n",
    "\n",
    "def max_tweet(sequences):\n",
    "    max_length=0\n",
    "    for i in range(len(sequences)):\n",
    "        if(len(sequences[i])>max_length):\n",
    "            max_length=len(sequences[i])\n",
    "       \n",
    "    return max_length\n",
    "\n",
    "sequences, tokenizer=tokenizer_data(list_tweets)\n",
    "\n",
    "print(len(tokenizer.word_index))\n",
    "max_length=max_tweet(sequences)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "korean-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(list_tweets,g_model):\n",
    "    print(list_tweets)\n",
    "    sequences, tokenizer=tokenizer_data(list_tweets)\n",
    "    sequences= pad_sequences(sequences, maxlen=70, padding='post')\n",
    "    result = g_model.predict(sequences, batch_size=3, verbose=0)\n",
    "    print(result)\n",
    "    res=[]\n",
    "    for i in range(len(result)):\n",
    "        predicted_word = ''\n",
    "        for j in range(len(result[i])):\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == int(result[i][j][0]):\n",
    "                    predicted_word = predicted_word+' '+word\n",
    "                    break\n",
    "        res.append(predicted_word)\n",
    "    #print(res)\n",
    "    for i in res:\n",
    "        print(i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "normal-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_text(model_disc, seed_text):\n",
    "    print(seed_text)\n",
    "    sequences, tokenizer=tokenizer_data(seed_text)\n",
    "    sequences= pad_sequences(sequences, maxlen=70, padding='post')\n",
    "    y = model_disc.predict([sequences], batch_size=3, verbose=0)\n",
    "    print(y)\n",
    "    for i in y:\n",
    "        if(i<0.6):\n",
    "            print(\"fake\")\n",
    "        else:\n",
    "            print(\"real\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "atlantic-immune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 70, 1)\n",
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 70, 1)]           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 60)                14880     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 70, 60)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 70, 60)            29040     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 70, 1)             61        \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            [(None, 70)]              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 70, 1)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 49,022\n",
      "Trainable params: 49,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 70, 1)]           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30)                3840      \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 70, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 70, 30)            7320      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 70, 1)             31        \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            [(None, 70)]              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "lambda_7 (Lambda)            (None, 70, 1)             0         \n",
      "=================================================================\n",
      "Total params: 16,161\n",
      "Trainable params: 16,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Tensor(\"functional_9/lambda_7/stack:0\", shape=(None, 70, 1), dtype=float32)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_9 (Functional)    (None, 70, 1)             16161     \n",
      "_________________________________________________________________\n",
      "functional_7 (Functional)    (None, 1)                 49022     \n",
      "=================================================================\n",
      "Total params: 65,183\n",
      "Trainable params: 16,161\n",
      "Non-trainable params: 49,022\n",
      "_________________________________________________________________\n",
      "None\n",
      "(22, 1)\n",
      "(22, 70)\n",
      "(22, 70, 1)\n",
      "epoch: 1/10, d_loss: 175226.16,   d_acc: 0.12, g_loss: 0.69\n",
      "epoch: 2/10, d_loss: 67445.98,   d_acc: 0.25, g_loss: 0.69\n",
      "epoch: 3/10, d_loss: 16190.06,   d_acc: 0.39, g_loss: 0.69\n",
      "epoch: 4/10, d_loss: 82873.16,   d_acc: 0.81, g_loss: 0.70\n",
      "epoch: 5/10, d_loss: 114558.86,   d_acc: 0.75, g_loss: 0.70\n",
      "epoch: 6/10, d_loss: 88637.95,   d_acc: 0.83, g_loss: 0.70\n",
      "epoch: 7/10, d_loss: 59148.03,   d_acc: 0.83, g_loss: 0.71\n",
      "epoch: 8/10, d_loss: 201419.81,   d_acc: 0.80, g_loss: 0.71\n",
      "epoch: 9/10, d_loss: 284564.18,   d_acc: 0.70, g_loss: 0.71\n",
      "epoch: 10/10, d_loss: 69518.40,   d_acc: 0.77, g_loss: 0.71\n"
     ]
    }
   ],
   "source": [
    "# train a generative adversarial network on a one-dimensional function\n",
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from matplotlib import pyplot\n",
    " \n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(n_inputs=70):\n",
    "    model = Sequential()\n",
    "    x0=Input(shape=(70, 1))\n",
    "    #x1=Flatten()(x0)\n",
    "    x2=LSTM(60, activation='relu', input_shape=(70, 1))(x0)\n",
    "    x3=RepeatVector(70)(x2)\n",
    "    x4=LSTM(60, activation='relu', return_sequences=True)(x3)\n",
    "    x5=TimeDistributed(Dense(1))(x4)\n",
    "    unstacked = Lambda(lambda x: tensorflow.unstack(x, axis=2))(x5)\n",
    "    dense_outputs = [Dense(70)(x) for x in unstacked]\n",
    "    merged = Lambda(lambda x: K.stack(x, axis=2))(dense_outputs)\n",
    "    x1=Flatten()(merged)\n",
    "    x6=Dense(1, activation='sigmoid')(x1)\n",
    "    model = Model(x0, x6)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_outputs=70):\n",
    "    model = Sequential()\n",
    "    x0=Input(shape=(latent_dim,1))\n",
    "    x1=LSTM(30, activation='relu', input_shape=(n_outputs,1))(x0)\n",
    "    # repeat vector\n",
    "    x2=RepeatVector(n_outputs)(x1)\n",
    "    # decoder layer\n",
    "    x3=LSTM(30, activation='relu', return_sequences=True)(x2)\n",
    "    x4=TimeDistributed(Dense(1))(x3)\n",
    "    unstacked = Lambda(lambda x: tensorflow.unstack(x, axis=2))(x4)\n",
    "    dense_outputs = [Dense(70)(x) for x in unstacked]\n",
    "\n",
    "    merged = Lambda(lambda x: K.stack(x, axis=2))(dense_outputs)\n",
    "\n",
    "    model = Model(x0, merged)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the discriminator\n",
    "    model.add(discriminator)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    " \n",
    "# generate n real samples with class labels\n",
    "def generate_real_samples():\n",
    "    list_real_tweets=prepare_data('c:/real_tweets.txt')\n",
    "    sequences, vocab_size=tokenizer_data(list_real_tweets)\n",
    "    max_length=max_tweet(sequences)\n",
    "    sequences = pad_sequences(sequences, maxlen=70, padding='post')\n",
    "    labels_real = np.ones((len(list_real_tweets), 1))\n",
    "    \n",
    "    return sequences,labels_real\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points():\n",
    "    list_tweets=prepare_data('C:/tweet.txt')\n",
    "    sequences, tokenizer=tokenizer_data(list_tweets)\n",
    "    max_length=max_tweet(sequences)\n",
    "    X =sequences[:33]\n",
    "    X = pad_sequences(X, maxlen=70, padding='post')\n",
    "    y =sequences[33:]\n",
    "    y = pad_sequences(y, maxlen=70, padding='post')\n",
    "    X=X.reshape(33, 70, 1)\n",
    "    y=y.reshape(33, 70, 1)\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "    return X_train,Y_train,X_test,Y_test\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator):\n",
    "    # generate points in latent space\n",
    "    X_train,X_test,Y_train,Y_test = generate_latent_points()\n",
    "    # predict outputs\n",
    "    X = generator.predict(X_train)\n",
    "    # create class labels\n",
    "    y = np.zeros((22, 1))\n",
    "    return X, y\n",
    "\n",
    " \n",
    "# evaluate the discriminator and plot real and fake points\n",
    "def summarize_performance(epoch, generator, discriminator, latent_dim, n=100):\n",
    "    # prepare real samples\n",
    "    x_real, y_real = generate_real_samples()\n",
    "    X_train,X_test,Y_train,Y_test = generate_latent_points()\n",
    "    # evaluate discriminator on real examples\n",
    "    acc_real = discriminator.evaluate(X_train, y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(generator)\n",
    "    # evaluate discriminator on fake examples\n",
    "    acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "    # summarize discriminator performance\n",
    "    print(epoch, acc_real, acc_fake)\n",
    "    # scatter plot real and fake data points\n",
    "    #pyplot.scatter(x_real[:, 0], x_real[:, 1], color='red')\n",
    "    #pyplot.scatter(x_fake[:, 0], x_fake[:, 1], color='blue')\n",
    "    #pyplot.show()\n",
    " \n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs=1, n_batch=128, n_eval=2):\n",
    "    # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    x_real, y_real = generate_real_samples()\n",
    "    print(y_real.shape)\n",
    "    print(x_real.shape)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(g_model)\n",
    "    X_train,X_test,Y_train,Y_test = generate_latent_points()\n",
    "    print(X_train.shape)\n",
    "    y_gan = ones((22, 1))\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        # update discriminator\n",
    "        d_model.train_on_batch(x_real, y_real)\n",
    "        d_model.evaluate(x_real, y_real)\n",
    "        d_model.train_on_batch(x_fake, y_fake)\n",
    "        d_model.evaluate(x_fake, y_fake)\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_model.train_on_batch(X_train, y_gan)\n",
    "        gan_model.evaluate(X_train, y_gan)\n",
    "        generate_tweets=generate(list_tweets[3:5],g_model)\n",
    "        print(\"list_tweets[3:5]\")\n",
    "        print(list_tweets[3:5])\n",
    "        print(\"generate_tweets\")\n",
    "        print(generate_tweets)\n",
    "        disc_text(d_model,generate_tweets)\n",
    "        # evaluate the model every n_eval epochs\n",
    "        print(i)\n",
    "        print((i+1)% n_eval)\n",
    "        #if (i+1) % n_eval == 0:\n",
    "        summarize_performance(i, g_model, d_model, latent_dim)\n",
    "\n",
    "\n",
    "# size of the latent space\n",
    "latent_dim = 70\n",
    "# Create an input to represent noise sample from latent space\n",
    "noise = Input(shape=(latent_dim,1))\n",
    "\n",
    "print(noise.shape)\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "tweet = generator(noise)\n",
    "print(tweet)\n",
    "discriminator.trainable = False\n",
    "fake_pred = discriminator(tweet)\n",
    "combined_model_gen = Model(noise, fake_pred)\n",
    "combined_model_gen.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "sample_period = 200\n",
    "# Create batch labels to use when calling train_on_batch\n",
    "ones = np.ones(batch_size)\n",
    "zeros = np.zeros(batch_size)\n",
    "\n",
    "# Store the losses\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "# Create a folder to store generated images\n",
    "#if not os.path.exists('gan_images'):\n",
    " # os.makedirs('gan_images')\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "x_real, y_real = generate_real_samples()\n",
    "print(y_real.shape)\n",
    "print(x_real.shape)\n",
    "# prepare fake examples\n",
    "x_fake, y_fake = generate_fake_samples(generator)\n",
    "X_train,X_test,Y_train,Y_test = generate_latent_points()\n",
    "print(X_train.shape)\n",
    "y_gan = np.ones((22, 1))\n",
    "# train model\n",
    "#train(generator, discriminator, gan_model, latent_dim)\n",
    "# Main training loop\n",
    "for epoch in range(epochs):\n",
    "  ###########################\n",
    "  ### Train discriminator ###\n",
    "  ###########################\n",
    "  \n",
    "  # Select a random batch of images\n",
    "  idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "  real_imgs = X_train[idx]\n",
    "  \n",
    "  # Generate fake images\n",
    "  noise = np.random.randn(batch_size, latent_dim)\n",
    "  fake_imgs = generator.predict(noise)\n",
    "  \n",
    "  # Train the discriminator\n",
    "  # both loss and accuracy are returned\n",
    "  d_loss_real, d_acc_real = discriminator.train_on_batch(real_imgs, ones)\n",
    "  d_loss_fake, d_acc_fake = discriminator.train_on_batch(fake_imgs, zeros)\n",
    "  d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "  d_acc  = 0.5 * (d_acc_real + d_acc_fake)\n",
    "  \n",
    "  \n",
    "  #######################\n",
    "  ### Train generator ###\n",
    "  #######################\n",
    "  \n",
    "  noise = np.random.randn(batch_size, latent_dim)\n",
    "  g_loss = combined_model_gen.train_on_batch(noise, ones)\n",
    "  \n",
    "  # do it again!\n",
    "  noise = np.random.randn(batch_size, latent_dim)\n",
    "  g_loss = combined_model_gen.train_on_batch(noise, ones)\n",
    "  \n",
    "  # Save the losses\n",
    "  d_losses.append(d_loss)\n",
    "  g_losses.append(g_loss)\n",
    "  \n",
    "  #if epoch % 100 == 0:\n",
    "  print(f\"epoch: {epoch+1}/{epochs}, d_loss: {d_loss:.2f}, \\\n",
    "  d_acc: {d_acc:.2f}, g_loss: {g_loss:.2f}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-adelaide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-venice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
