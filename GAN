{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "champion-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import LSTM,Dense,Input,ConvLSTM2D,Reshape,Activation,Lambda,Softmax\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras.backend as kerback\n",
    "from keras.models import Model\n",
    "import tensorflow \n",
    "from keras.datasets.mnist import load_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "diverse-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.tweet_length = 100\n",
    "        #self.tweet_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def data_load(self):\n",
    "        pd.__version__\n",
    "        df = pd.read_csv('C:/Users/LENOVO/Desktop/PCD/tweet.txt', sep=\"\\n\",header=None)\n",
    "        list_listword=[]#liste des listes des mots de chaque tweet\n",
    "        list_tweets=df[0].values.tolist()#liste des tweets\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(list_tweets)\n",
    "        sequences = tokenizer.texts_to_sequences(list_tweets)\n",
    "        vocab_size=len(tokenizer.word_index)\n",
    "        max_length=0\n",
    "        for i in range(len(sequences)):\n",
    "            if(len(sequences[i])>max_length):\n",
    "              max_length=len(sequences[i])\n",
    "        X =sequences[:33]\n",
    "        X = pad_sequences(X, maxlen=max_length, padding='post')\n",
    "        y =sequences[33:]\n",
    "        y = pad_sequences(y, maxlen=max_length, padding='post')\n",
    "        X=X.reshape(33, max_length, 1)\n",
    "        y=y.reshape(33, max_length, 1)\n",
    "        X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.33)\n",
    "        return X_train,Y_train,X_test,Y_test\n",
    "    \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        x0=Input(shape=(57, 1))\n",
    "# encoder layer\n",
    "        x1=LSTM(15, activation='relu', input_shape=(57, 1))(x0)\n",
    "# repeat vector\n",
    "        x2=RepeatVector(57)(x1)\n",
    "# decoder layer\n",
    "        x3=LSTM(15, activation='relu', return_sequences=True)(x2)\n",
    "#model.add(LSTM(10, activation='relu', return_sequences=True))\n",
    "        x4=TimeDistributed(Dense(1))(x3)\n",
    "#x4=TimeDistributed(Dense(1))\n",
    "        unstacked = Lambda(lambda x: tensorflow.unstack(x, axis=2))(x4)\n",
    "        dense_outputs = [Dense(57)(x) for x in unstacked]\n",
    "#print(unstacked)\n",
    "        merged = Lambda(lambda x: K.stack(x, axis=2))(dense_outputs)\n",
    "#y6=Softmax(axis=-1)(merged)\n",
    "\n",
    "        return Model(x0, merged)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        x0=Input(shape=(70,1))\n",
    "# encoder layer\n",
    "        x1=LSTM(15, activation='relu', input_shape=(70,1))(x0)\n",
    "# repeat vector\n",
    "        x2=RepeatVector(70)(x1)\n",
    "# decoder layer\n",
    "        x3=LSTM(15, activation='relu', return_sequences=True)(x2)\n",
    "#model.add(TimeDistributed(Dense(1)))\n",
    "        x4=TimeDistributed(Dense(1))(x3)\n",
    "        unstacked = Lambda(lambda x: tensorflow.unstack(x, axis=2))(x4)\n",
    "        dense_outputs = [Dense(1)(x) for x in unstacked]\n",
    "        merged = Lambda(lambda x: K.stack(x, axis=2))(dense_outputs)\n",
    "        return Model(x0, merged)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        X_train,Y_train,X_test,Y_test = self.data_load()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "                \n",
    "            print(\"fin\")\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        \"\"\"\"\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        #gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        #fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        #fig.savefig(\"gan/images/mnist_%d.png\" % epoch)\n",
    "        #plt.close()\n",
    "        \"\"\"\n",
    "        tokenizer = Tokenizer()\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        print(noise)\n",
    "        result = self.generator.predict(noise)\n",
    "        print(result)\n",
    "        #print(\"res\",gen_imgs)\n",
    "        res=[]\n",
    "        for i in range(len(result)):\n",
    "            predicted_word = ''\n",
    "            for j in range(len(result[i])):\n",
    "               for word, index in tokenizer.word_index.items():\n",
    "       \n",
    "                  if index == int(result[i][j][0]):\n",
    "                     predicted_word = predicted_word+' '+word\n",
    "                     print(\"pre\",predicted_word)\n",
    "                     break\n",
    "            res.append(predicted_word)   \n",
    "        for i in res:\n",
    "           print(\"h\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "intense-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 57, 1) for input Tensor(\"input_38:0\", shape=(None, 57, 1), dtype=float32), but it was called on an input with incompatible shape (None, 100, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 70, 1) for input Tensor(\"input_37:0\", shape=(None, 70, 1), dtype=float32), but it was called on an input with incompatible shape (None, 57, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 57, 1) for input Tensor(\"input_38:0\", shape=(None, 57, 1), dtype=float32), but it was called on an input with incompatible shape (None, 100, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 70, 1) for input Tensor(\"input_37:0\", shape=(None, 70, 1), dtype=float32), but it was called on an input with incompatible shape (16, 57, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 70, 1) for input Tensor(\"input_37:0\", shape=(None, 70, 1), dtype=float32), but it was called on an input with incompatible shape (16, 57, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 70, 1) for input Tensor(\"input_37:0\", shape=(None, 70, 1), dtype=float32), but it was called on an input with incompatible shape (16, 57, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 57, 1) for input Tensor(\"input_38:0\", shape=(None, 57, 1), dtype=float32), but it was called on an input with incompatible shape (32, 100, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 70, 1) for input Tensor(\"input_37:0\", shape=(None, 70, 1), dtype=float32), but it was called on an input with incompatible shape (32, 57, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 57, 1) for input Tensor(\"input_38:0\", shape=(None, 57, 1), dtype=float32), but it was called on an input with incompatible shape (32, 100, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 70, 1) for input Tensor(\"input_37:0\", shape=(None, 70, 1), dtype=float32), but it was called on an input with incompatible shape (32, 57, 1).\n",
      "0 [D loss: 1.962643, acc.: 50.00%] [G loss: 9.563312]\n",
      "[[ 4.68140423e-01  2.65883905e-01  1.06109489e-03 ...  2.01444163e+00\n",
      "  -6.10585710e-01  8.40400569e-01]\n",
      " [-5.47744392e-02  8.25579085e-01  1.32481747e-01 ... -1.01770257e+00\n",
      "   8.99810916e-02 -3.06955174e-01]\n",
      " [-8.83580472e-01 -6.48859946e-01  1.23579658e-01 ...  8.36248733e-01\n",
      "  -6.70553046e-01 -1.35963774e+00]\n",
      " ...\n",
      " [-1.22728345e+00  2.02359818e-01 -8.06209467e-02 ...  3.23653393e-01\n",
      "  -3.96883430e-01  4.79965787e-01]\n",
      " [-1.16728563e+00 -5.28988157e-02  2.25290042e-01 ...  1.02804152e+00\n",
      "  -1.19703779e+00 -2.17904049e-01]\n",
      " [-1.56688512e+00  3.23011657e-01  8.69406470e-01 ... -2.66674309e-01\n",
      "  -2.35366951e-01 -9.19931087e-01]]\n",
      "[[[ 0.06397532]\n",
      "  [ 0.0158135 ]\n",
      "  [ 0.12602815]\n",
      "  ...\n",
      "  [ 0.09149583]\n",
      "  [-0.03535868]\n",
      "  [-0.01004488]]\n",
      "\n",
      " [[-0.03303865]\n",
      "  [-0.00648431]\n",
      "  [-0.06555356]\n",
      "  ...\n",
      "  [-0.05111442]\n",
      "  [ 0.0086838 ]\n",
      "  [ 0.00564197]]\n",
      "\n",
      " [[-0.07132605]\n",
      "  [-0.01452594]\n",
      "  [-0.14183326]\n",
      "  ...\n",
      "  [-0.10986917]\n",
      "  [ 0.02095872]\n",
      "  [ 0.01239343]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.01836988]\n",
      "  [ 0.00429444]\n",
      "  [ 0.03601418]\n",
      "  ...\n",
      "  [ 0.02640752]\n",
      "  [-0.00701841]\n",
      "  [-0.00317536]]\n",
      "\n",
      " [[ 0.01049944]\n",
      "  [ 0.0025206 ]\n",
      "  [ 0.02075792]\n",
      "  ...\n",
      "  [ 0.01533968]\n",
      "  [-0.00457259]\n",
      "  [-0.00193354]]\n",
      "\n",
      " [[-0.05184903]\n",
      "  [-0.01068441]\n",
      "  [-0.10303744]\n",
      "  ...\n",
      "  [-0.07953619]\n",
      "  [ 0.01598532]\n",
      "  [ 0.00885886]]]\n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "h \n",
      "fin\n",
      "1 [D loss: 1.900711, acc.: 50.00%] [G loss: 7.328312]\n",
      "fin\n",
      "2 [D loss: 1.852355, acc.: 50.00%] [G loss: 6.750087]\n",
      "fin\n",
      "3 [D loss: 1.771007, acc.: 50.00%] [G loss: 6.354766]\n",
      "fin\n",
      "4 [D loss: 1.743458, acc.: 50.00%] [G loss: 6.079060]\n",
      "fin\n",
      "5 [D loss: 1.749501, acc.: 50.00%] [G loss: 5.862907]\n",
      "fin\n",
      "6 [D loss: 1.642630, acc.: 50.00%] [G loss: 5.608487]\n",
      "fin\n",
      "7 [D loss: 1.611329, acc.: 50.00%] [G loss: 5.629883]\n",
      "fin\n",
      "8 [D loss: 1.571806, acc.: 50.00%] [G loss: 5.438082]\n",
      "fin\n",
      "9 [D loss: 1.566929, acc.: 50.00%] [G loss: 5.365921]\n",
      "fin\n",
      "10 [D loss: 1.553790, acc.: 50.00%] [G loss: 5.309624]\n",
      "fin\n",
      "11 [D loss: 1.468715, acc.: 50.00%] [G loss: 5.119629]\n",
      "fin\n",
      "12 [D loss: 1.467040, acc.: 50.00%] [G loss: 5.107072]\n",
      "fin\n",
      "13 [D loss: 1.397793, acc.: 50.00%] [G loss: 5.025256]\n",
      "fin\n",
      "14 [D loss: 1.395131, acc.: 50.00%] [G loss: 4.940947]\n",
      "fin\n",
      "15 [D loss: 1.350946, acc.: 50.00%] [G loss: 4.827332]\n",
      "fin\n",
      "16 [D loss: 1.364427, acc.: 50.00%] [G loss: 4.888821]\n",
      "fin\n",
      "17 [D loss: 1.298307, acc.: 50.00%] [G loss: 4.771271]\n",
      "fin\n",
      "18 [D loss: 1.318125, acc.: 50.00%] [G loss: 4.793533]\n",
      "fin\n",
      "19 [D loss: 1.239051, acc.: 50.00%] [G loss: 4.864220]\n",
      "fin\n",
      "20 [D loss: 1.252990, acc.: 50.00%] [G loss: 4.789324]\n",
      "fin\n",
      "21 [D loss: 1.174361, acc.: 50.00%] [G loss: 4.755263]\n",
      "fin\n",
      "22 [D loss: 1.145994, acc.: 50.00%] [G loss: 4.707234]\n",
      "fin\n",
      "23 [D loss: 1.140702, acc.: 50.00%] [G loss: 4.669234]\n",
      "fin\n",
      "24 [D loss: 1.156347, acc.: 50.00%] [G loss: 4.775405]\n",
      "fin\n",
      "25 [D loss: 1.130140, acc.: 50.00%] [G loss: 4.707358]\n",
      "fin\n",
      "26 [D loss: 1.103163, acc.: 50.00%] [G loss: 4.732810]\n",
      "fin\n",
      "27 [D loss: 1.083209, acc.: 50.00%] [G loss: 4.875917]\n",
      "fin\n",
      "28 [D loss: 1.067031, acc.: 50.00%] [G loss: 4.592674]\n",
      "fin\n",
      "29 [D loss: 1.025952, acc.: 50.00%] [G loss: 4.767820]\n",
      "fin\n",
      "30 [D loss: 1.032296, acc.: 50.00%] [G loss: 4.763423]\n",
      "fin\n",
      "31 [D loss: 1.014002, acc.: 50.00%] [G loss: 4.809223]\n",
      "fin\n",
      "32 [D loss: 0.988183, acc.: 50.00%] [G loss: 4.767800]\n",
      "fin\n",
      "33 [D loss: 0.952617, acc.: 50.00%] [G loss: 4.855485]\n",
      "fin\n",
      "34 [D loss: 0.909234, acc.: 50.00%] [G loss: 4.951846]\n",
      "fin\n",
      "35 [D loss: 0.931276, acc.: 50.00%] [G loss: 5.155007]\n",
      "fin\n",
      "36 [D loss: 0.869247, acc.: 50.00%] [G loss: 5.161025]\n",
      "fin\n",
      "37 [D loss: 0.877791, acc.: 50.00%] [G loss: 6.501698]\n",
      "fin\n",
      "38 [D loss: 0.850392, acc.: 50.00%] [G loss: 5.750406]\n",
      "fin\n",
      "39 [D loss: 0.824534, acc.: 50.00%] [G loss: 6.471169]\n",
      "fin\n",
      "40 [D loss: 0.845448, acc.: 50.00%] [G loss: 5.576125]\n",
      "fin\n",
      "41 [D loss: 0.855558, acc.: 50.00%] [G loss: 5.994906]\n",
      "fin\n",
      "42 [D loss: 0.778065, acc.: 50.00%] [G loss: 7.069971]\n",
      "fin\n",
      "43 [D loss: 0.757003, acc.: 50.00%] [G loss: 7.551237]\n",
      "fin\n",
      "44 [D loss: 0.757523, acc.: 50.00%] [G loss: 7.507559]\n",
      "fin\n",
      "45 [D loss: 0.733357, acc.: 50.00%] [G loss: 5.035436]\n",
      "fin\n",
      "46 [D loss: 0.729854, acc.: 50.00%] [G loss: 5.943695]\n",
      "fin\n",
      "47 [D loss: 0.687633, acc.: 50.00%] [G loss: 5.321694]\n",
      "fin\n",
      "48 [D loss: 0.677450, acc.: 50.00%] [G loss: 5.747521]\n",
      "fin\n",
      "49 [D loss: 0.651946, acc.: 50.00%] [G loss: 4.312745]\n",
      "fin\n",
      "50 [D loss: 0.650124, acc.: 50.00%] [G loss: 7.245254]\n",
      "fin\n",
      "51 [D loss: 0.621476, acc.: 50.00%] [G loss: 5.322974]\n",
      "fin\n",
      "52 [D loss: 0.619782, acc.: 50.00%] [G loss: 4.717706]\n",
      "fin\n",
      "53 [D loss: 0.603193, acc.: 53.12%] [G loss: 4.180527]\n",
      "fin\n",
      "54 [D loss: 0.518883, acc.: 56.25%] [G loss: 3.650603]\n",
      "fin\n",
      "55 [D loss: 0.528925, acc.: 53.12%] [G loss: 3.529972]\n",
      "fin\n",
      "56 [D loss: 0.469042, acc.: 59.38%] [G loss: 3.412760]\n",
      "fin\n",
      "57 [D loss: 0.431113, acc.: 65.62%] [G loss: 5.058027]\n",
      "fin\n",
      "58 [D loss: 0.417402, acc.: 62.50%] [G loss: 3.571458]\n",
      "fin\n",
      "59 [D loss: 0.348135, acc.: 81.25%] [G loss: 4.397431]\n",
      "fin\n",
      "60 [D loss: 0.301177, acc.: 81.25%] [G loss: 4.127871]\n",
      "fin\n",
      "61 [D loss: 0.298243, acc.: 84.38%] [G loss: 3.462979]\n",
      "fin\n",
      "62 [D loss: 0.442980, acc.: 71.88%] [G loss: 3.153804]\n",
      "fin\n",
      "63 [D loss: 0.326016, acc.: 75.00%] [G loss: 2.504631]\n",
      "fin\n",
      "64 [D loss: 0.195007, acc.: 93.75%] [G loss: 3.447393]\n",
      "fin\n",
      "65 [D loss: 0.816404, acc.: 75.00%] [G loss: 2.433378]\n",
      "fin\n",
      "66 [D loss: 0.231866, acc.: 93.75%] [G loss: 3.498759]\n",
      "fin\n",
      "67 [D loss: 0.829430, acc.: 84.38%] [G loss: 2.193957]\n",
      "fin\n",
      "68 [D loss: 0.773088, acc.: 81.25%] [G loss: 2.889530]\n",
      "fin\n",
      "69 [D loss: 1.528282, acc.: 59.38%] [G loss: 3.264423]\n",
      "fin\n",
      "70 [D loss: 2.322881, acc.: 62.50%] [G loss: 3.828619]\n",
      "fin\n",
      "71 [D loss: 1.513417, acc.: 62.50%] [G loss: 2.349887]\n",
      "fin\n",
      "72 [D loss: 2.354699, acc.: 62.50%] [G loss: 3.825811]\n",
      "fin\n",
      "73 [D loss: 1.977976, acc.: 62.50%] [G loss: 3.712817]\n",
      "fin\n",
      "74 [D loss: 1.995426, acc.: 43.75%] [G loss: 5.367565]\n",
      "fin\n",
      "75 [D loss: 3.472106, acc.: 28.12%] [G loss: 4.333842]\n",
      "fin\n",
      "76 [D loss: 2.540192, acc.: 31.25%] [G loss: 4.433179]\n",
      "fin\n",
      "77 [D loss: 2.991734, acc.: 31.25%] [G loss: 4.713482]\n",
      "fin\n",
      "78 [D loss: 0.709394, acc.: 40.62%] [G loss: 4.090738]\n",
      "fin\n",
      "79 [D loss: 1.574161, acc.: 40.62%] [G loss: 2.677399]\n",
      "fin\n",
      "80 [D loss: 1.076587, acc.: 46.88%] [G loss: 3.846070]\n",
      "fin\n",
      "81 [D loss: 1.070688, acc.: 46.88%] [G loss: 3.496192]\n",
      "fin\n",
      "82 [D loss: 0.588740, acc.: 50.00%] [G loss: 2.766518]\n",
      "fin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 [D loss: 1.033933, acc.: 46.88%] [G loss: 3.129261]\n",
      "fin\n",
      "84 [D loss: 0.655071, acc.: 50.00%] [G loss: 3.732836]\n",
      "fin\n",
      "85 [D loss: 0.992285, acc.: 46.88%] [G loss: 5.759511]\n",
      "fin\n",
      "86 [D loss: 0.614196, acc.: 46.88%] [G loss: 3.820352]\n",
      "fin\n",
      "87 [D loss: 1.086492, acc.: 46.88%] [G loss: 2.611580]\n",
      "fin\n",
      "88 [D loss: 0.542913, acc.: 53.12%] [G loss: 2.903053]\n",
      "fin\n",
      "89 [D loss: 0.597030, acc.: 50.00%] [G loss: 2.989499]\n",
      "fin\n",
      "90 [D loss: 1.030532, acc.: 46.88%] [G loss: 2.449905]\n",
      "fin\n",
      "91 [D loss: 2.847407, acc.: 37.50%] [G loss: 2.063430]\n",
      "fin\n",
      "92 [D loss: 0.561576, acc.: 59.38%] [G loss: 2.989176]\n",
      "fin\n",
      "93 [D loss: 1.488541, acc.: 43.75%] [G loss: 2.436718]\n",
      "fin\n",
      "94 [D loss: 1.936301, acc.: 46.88%] [G loss: 3.090353]\n",
      "fin\n",
      "95 [D loss: 0.531954, acc.: 56.25%] [G loss: 2.624015]\n",
      "fin\n",
      "96 [D loss: 1.019837, acc.: 50.00%] [G loss: 3.080405]\n",
      "fin\n",
      "97 [D loss: 0.486316, acc.: 46.88%] [G loss: 3.086883]\n",
      "fin\n",
      "98 [D loss: 0.588378, acc.: 53.12%] [G loss: 2.344896]\n",
      "fin\n",
      "99 [D loss: 0.478594, acc.: 59.38%] [G loss: 3.529482]\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "    gan = GAN()\n",
    "    gan.train(epochs=100, batch_size=32, save_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-lecture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-experience",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
