{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "advisory-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Input,ConvLSTM2D,Reshape,Activation,Lambda,Softmax,Concatenate\n",
    "from keras.layers import Dense, LSTM, Input, Embedding, TimeDistributed, Flatten, Dropout,RepeatVector,Reshape,Activation,Lambda,Softmax\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import keras.backend as kerback\n",
    "#from keras.models import Model\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.preprocessing.text import one_hot\n",
    "import tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "responsible-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a generative adversarial network on a one-dimensional function\n",
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import random\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "municipal-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(f):\n",
    "    data = pd.read_csv(f, sep=\"\\n\",header=None)\n",
    "    list_listword=[]#liste des listes des mots de chaque tweet\n",
    "    list_tweets=data[0].values.tolist()#liste des tweets\n",
    "    l=[]\n",
    "    for text in list_tweets:\n",
    "        text = re.sub(r'http\\S+', '', text)   # Remove URLs\n",
    "        text = re.sub(r'â€”', ' ', text) \n",
    "        text = re.sub(r'@[a-zA-Z0-9_]+', '', text)  # Remove @ mentions\n",
    "        text = text.strip(\" \")   # Remove whitespace resulting from above\n",
    "        text = re.sub(r' +', ' ', text)   # Remove redundant spaces\n",
    "        l.append(text)\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "persistent-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tweets=prepare_data('C:/Users/LENOVO/Desktop/PCD/tweet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "continuous-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146, 7, 46, 5, 2, 147, 148, 106, 3, 17, 149, 107, 1, 348, 349, 30, 350, 58, 351, 352, 3, 353, 354, 208, 52, 355, 356, 357, 7, 358, 3, 209, 47, 18, 359, 7, 360, 22, 4, 27]\n",
      "40\n",
      "57\n",
      "841\n"
     ]
    }
   ],
   "source": [
    "def tokenizer_data(list_tweets):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(list_tweets)\n",
    "    sequences = tokenizer.texts_to_sequences(list_tweets)\n",
    "    vocab_size=len(tokenizer.word_index)\n",
    "    return sequences, tokenizer, vocab_size\n",
    "\n",
    "def max_tweet(sequences):\n",
    "    max_length=0\n",
    "    for i in range(len(sequences)):\n",
    "        if(len(sequences[i])>max_length):\n",
    "            max_length=len(sequences[i])\n",
    "        #print(\"max\",max_length)\n",
    "        #print(\"seq=\",sequences)\n",
    "        #print(vocab_size)\n",
    "    return max_length\n",
    "\n",
    "sequences, tokenizer, vocab_size=tokenizer_data(list_tweets)\n",
    "print(sequences[0])\n",
    "print(len(sequences[0])) #nombre d'element de tweet zero\n",
    "nb_tweet=len(sequences)\n",
    "batch_size=22\n",
    "#print(len(tokenizer.word_index))\n",
    "max_length=max_tweet(sequences)#nombre d'element de tout les tweet pour les mettres egaux\n",
    "print(max_length)#############\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "convinced-linux",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer lstm_223 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 22, 57, 50]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-180-6c968e348c07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mbuild_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m57\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-180-6c968e348c07>\u001b[0m in \u001b[0;36mbuild_generator\u001b[1;34m(n_outputs)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtweet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mz0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mz1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m#z1=Reshape(( max_length, 50))(z0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1090\u001b[0m       \u001b[1;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m       \u001b[1;31m# are casted, not before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    174\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    177\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer lstm_223 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 22, 57, 50]"
     ]
    }
   ],
   "source": [
    "def build_generator(n_outputs=57):\n",
    "    model = Sequential()\n",
    "    \n",
    "    tweet=Input(shape=(22,n_outputs,))\n",
    "    z0=Embedding(vocab_size+1,50, input_length=max_length)(tweet)\n",
    "    z1=LSTM(units=1000)(z0)\n",
    "    #z1=Reshape(( max_length, 50))(z0)\n",
    "    print(z0.shape)\n",
    "    noise=Input(shape=(22,n_outputs, 1))\n",
    "    out=Embedding(vocab_size+1,50, input_length=max_length)(noise)\n",
    "    out1=LSTM(units=1000)(out)\n",
    "    #out2=Dense(units=50)(out1)\n",
    "    #out2=Reshape(( max_length, 50) )(out2)\n",
    "    print(out2)\n",
    "    OO1=Concatenate(axis=2)([z1,out2])\n",
    "    print(OO1.shape)\n",
    "    #x0=Reshape((-1,max_length,50,2))(OO1)\n",
    "\n",
    "    \n",
    "    x1=LSTM(15, activation='relu', input_shape=(n_outputs,1),batch_size=20)(OO1)\n",
    "    #15 nombre de neurone ,batch_size=n_batch=20 \n",
    "    # repeat vector\n",
    "    x2=RepeatVector(n_outputs)(x1)\n",
    "    # decoder layer\n",
    "    x3=LSTM(15, activation='relu', return_sequences=True)(x2)\n",
    "    x4=TimeDistributed(Dense(1))(x3)\n",
    "    unstacked = Lambda(lambda x: tensorflow.unstack(x, axis=2))(x4)\n",
    "    dense_outputs = [Dense(57)(x) for x in unstacked]\n",
    "\n",
    "    merged = Lambda(lambda x: K.stack(x, axis=2))(dense_outputs)\n",
    "\n",
    "    model = Model([noise,tweet], merged)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    print('generator')\n",
    "    print(model.summary())\n",
    "    return model\n",
    "build_generator(n_outputs=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bigger-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 57, 50)\n",
      "(None, 57, 100)\n",
      "discriminator\n",
      "Model: \"functional_129\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_196 (InputLayer)          [(None, 57, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_206 (LSTM)                 (None, 57, 1000)     4008000     input_196[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_195 (InputLayer)          [(None, 57)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_233 (Dense)               (None, 57, 50)       50050       lstm_206[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_72 (Embedding)        (None, 57, 50)       42100       input_195[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 57, 100)      0           dense_233[0][0]                  \n",
      "                                                                 embedding_72[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_207 (LSTM)                 (None, 15)           6960        concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_64 (RepeatVector) (None, 57, 15)       0           lstm_207[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_208 (LSTM)                 (None, 57, 15)       1860        repeat_vector_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_64 (TimeDistri (None, 57, 1)        16          lstm_208[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_128 (Lambda)             [(None, 57)]         0           time_distributed_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_235 (Dense)               (None, 57)           3306        lambda_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_129 (Lambda)             (None, 57, 1)        0           dense_235[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 57)           0           lambda_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_236 (Dense)               (None, 1)            58          flatten_33[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,112,350\n",
      "Trainable params: 4,112,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x14bd89a9cd0>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_discriminator(n_outputs):\n",
    "    model = Sequential()\n",
    "    #x0=Input(shape=(tweet_size, 1))\n",
    "    #x1=Flatten()(x0)\n",
    "    tweet=Input(shape=(n_outputs,))\n",
    "    z0=Embedding(vocab_size+1,50, input_length=max_length)(tweet)\n",
    "    print(z0.shape)\n",
    "    #z1=Reshape(( max_length, 50))(z0)\n",
    "    \n",
    "    noise=Input(shape=(n_outputs, 1))\n",
    "    out1=LSTM(units=1000, return_state=False,return_sequences=True)(noise)\n",
    "    out2=Dense(units=50)(out1)\n",
    "    #out2=Reshape(( max_length, 50) )(out2)\n",
    "    \n",
    "    OO1=Concatenate(axis=2)([out2,z0])\n",
    "    print(OO1.shape)\n",
    "    \n",
    "    x2=LSTM(15, activation='relu', input_shape=(n_outputs, 1))(OO1)\n",
    "    x3=RepeatVector(n_outputs)(x2)\n",
    "    x4=LSTM(15, activation='relu', return_sequences=True)(x3)\n",
    "    x5=TimeDistributed(Dense(1))(x4)\n",
    "    unstacked = Lambda(lambda x: tensorflow.unstack(x, axis=2))(x5)\n",
    "    dense_outputs = [Dense(n_outputs)(x) for x in unstacked]\n",
    "    merged = Lambda(lambda x: K.stack(x, axis=2))(dense_outputs)\n",
    "    x1=Flatten()(merged)\n",
    "    x6=Dense(1, activation='sigmoid')(x1)\n",
    "    model = Model([noise,tweet], x6)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    print('discriminator')\n",
    "    print(model.summary())\n",
    "    return model\n",
    "build_discriminator(57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "engaging-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 57, 100)\n",
      "generator\n",
      "Model: \"functional_131\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_198 (InputLayer)          [(None, 57, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_197 (InputLayer)          [(None, 57)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_209 (LSTM)                 (None, 57, 1000)     4008000     input_198[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_73 (Embedding)        (None, 57, 50)       42100       input_197[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_237 (Dense)               (None, 57, 50)       50050       lstm_209[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_101 (Reshape)           (None, 57, 50)       0           embedding_73[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_102 (Reshape)           (None, 57, 50)       0           dense_237[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 57, 100)      0           reshape_101[0][0]                \n",
      "                                                                 reshape_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_210 (LSTM)                 (None, 15)           6960        concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_65 (RepeatVector) (None, 57, 15)       0           lstm_210[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_211 (LSTM)                 (None, 57, 15)       1860        repeat_vector_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_65 (TimeDistri (None, 57, 1)        16          lstm_211[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_130 (Lambda)             [(None, 57)]         0           time_distributed_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_239 (Dense)               (None, 57)           3306        lambda_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_131 (Lambda)             (None, 57, 1)        0           dense_239[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,112,292\n",
      "Trainable params: 4,112,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(None, 57, 50)\n",
      "(None, 57, 100)\n",
      "discriminator\n",
      "Model: \"functional_133\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_200 (InputLayer)          [(None, 57, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_212 (LSTM)                 (None, 57, 1000)     4008000     input_200[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_199 (InputLayer)          [(None, 57)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_240 (Dense)               (None, 57, 50)       50050       lstm_212[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_74 (Embedding)        (None, 57, 50)       42100       input_199[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 57, 100)      0           dense_240[0][0]                  \n",
      "                                                                 embedding_74[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_213 (LSTM)                 (None, 15)           6960        concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_66 (RepeatVector) (None, 57, 15)       0           lstm_213[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_214 (LSTM)                 (None, 57, 15)       1860        repeat_vector_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_66 (TimeDistri (None, 57, 1)        16          lstm_214[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_132 (Lambda)             [(None, 57)]         0           time_distributed_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_242 (Dense)               (None, 57)           3306        lambda_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_133 (Lambda)             (None, 57, 1)        0           dense_242[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 57)           0           lambda_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_243 (Dense)               (None, 1)            58          flatten_34[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,112,350\n",
      "Trainable params: 4,112,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"gan\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_201 (InputLayer)          [(None, 57, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_202 (InputLayer)          [(None, 57, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_131 (Functional)     (None, 57, 1)        4112292     input_201[0][0]                  \n",
      "                                                                 input_202[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "functional_133 (Functional)     (None, 1)            4112350     functional_131[0][0]             \n",
      "                                                                 input_201[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,224,642\n",
      "Trainable params: 4,112,292\n",
      "Non-trainable params: 4,112,350\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the combined generator and discriminator model\n",
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    inputs = Input(shape=(57,1))\n",
    "    text_input = Input(shape=(57,1))\n",
    "    \n",
    "    text=generator([inputs,text_input])\n",
    "  \n",
    "    fake_pred = discriminator([text,inputs])\n",
    "    \n",
    "    gan = Model([inputs,text_input], fake_pred, name=\"gan\")\n",
    "    # compile model\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    print(gan.summary())\n",
    "define_gan(build_generator(57), build_discriminator(57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "promising-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(max_length):\n",
    "    list_tweets=prepare_data('C:/Users/LENOVO/Desktop/PCD/tweet.txt')\n",
    "    sequences, tokenizer, vocab_size=tokenizer_data(list_tweets)\n",
    "    #print(sequences[0])\n",
    "    #print(\"len=\",len(sequences[0]))\n",
    "    X=sequences[:33]\n",
    "    X=pad_sequences(X, maxlen=max_length, padding='post')\n",
    "    y=sequences[33:]\n",
    "    y=pad_sequences(y, maxlen=max_length, padding='post')\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.33)\n",
    "    max_length=max_tweet(sequences)\n",
    "    #t =sequences[:batch_size]#on a prix les 30 1er tweets\n",
    "    #t = pad_sequences(t, maxlen=max_length, padding='post')\n",
    "    #labels=sequences[:batch_size]\n",
    "    #y = ones((n_samples, 1))\n",
    "    #print(\"t:\",t.shape)\n",
    "    y = np.ones((batch_size, 1))\n",
    "    return [X_train,Y_train],y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "promotional-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim=57, n_samples=22, n_classes=vocab_size):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = random.randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
    "\t# generate labels\n",
    "\tlabels = random.randint(0, n_classes, n_samples)\n",
    "\treturn [z_input, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "primary-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim=57, n_samples=22):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    print(z_input.shape)\n",
    "    print(labels_input.shape)\n",
    "    # predict outputs\n",
    "    images = generator.predict([z_input, labels_input])\n",
    "    # create class labels\n",
    "    y = zeros((n_samples, 1))\n",
    "    return [images, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "blessed-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch labels to use when calling train_on_batch\n",
    "#y_real = ones((batch_size,1))\n",
    "#y_fake = zeros((batch_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dynamic-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 57, 100)\n",
      "generator\n",
      "Model: \"functional_135\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_204 (InputLayer)          [(None, 57, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_203 (InputLayer)          [(None, 57)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_215 (LSTM)                 (None, 57, 1000)     4008000     input_204[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_75 (Embedding)        (None, 57, 50)       42100       input_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_244 (Dense)               (None, 57, 50)       50050       lstm_215[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_103 (Reshape)           (None, 57, 50)       0           embedding_75[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_104 (Reshape)           (None, 57, 50)       0           dense_244[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 57, 100)      0           reshape_103[0][0]                \n",
      "                                                                 reshape_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_216 (LSTM)                 (None, 15)           6960        concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_67 (RepeatVector) (None, 57, 15)       0           lstm_216[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_217 (LSTM)                 (None, 57, 15)       1860        repeat_vector_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_67 (TimeDistri (None, 57, 1)        16          lstm_217[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_134 (Lambda)             [(None, 57)]         0           time_distributed_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_246 (Dense)               (None, 57)           3306        lambda_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_135 (Lambda)             (None, 57, 1)        0           dense_246[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,112,292\n",
      "Trainable params: 4,112,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(None, 57, 50)\n",
      "(None, 57, 100)\n",
      "discriminator\n",
      "Model: \"functional_137\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_206 (InputLayer)          [(None, 57, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_218 (LSTM)                 (None, 57, 1000)     4008000     input_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_205 (InputLayer)          [(None, 57)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_247 (Dense)               (None, 57, 50)       50050       lstm_218[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_76 (Embedding)        (None, 57, 50)       42100       input_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 57, 100)      0           dense_247[0][0]                  \n",
      "                                                                 embedding_76[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_219 (LSTM)                 (None, 15)           6960        concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_68 (RepeatVector) (None, 57, 15)       0           lstm_219[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_220 (LSTM)                 (None, 57, 15)       1860        repeat_vector_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_68 (TimeDistri (None, 57, 1)        16          lstm_220[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)             [(None, 57)]         0           time_distributed_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_249 (Dense)               (None, 57)           3306        lambda_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)             (None, 57, 1)        0           dense_249[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 57)           0           lambda_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_250 (Dense)               (None, 1)            58          flatten_35[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,112,350\n",
      "Trainable params: 4,112,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"gan\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_207 (InputLayer)          [(None, 57, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_208 (InputLayer)          [(None, 57, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_135 (Functional)     (None, 57, 1)        4112292     input_207[0][0]                  \n",
      "                                                                 input_208[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "functional_137 (Functional)     (None, 1)            4112350     functional_135[0][0]             \n",
      "                                                                 input_207[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,224,642\n",
      "Trainable params: 4,112,292\n",
      "Non-trainable params: 4,112,350\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator(max_length)\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator(max_length)\n",
    "#discriminator.compile(optimizer='adam', loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "\n",
    "# Build and compile the combined model\n",
    "gan_model = define_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "promising-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tweet(epoch,noise,g_model):\n",
    "    result = g_model.predict(noise)\n",
    "    #print(result)\n",
    "    #print(result.shape)\n",
    "    #print(len(result))\n",
    "    res=[]\n",
    "    predicted_word =\"\"\n",
    "    for j in range(57):\n",
    "        #predicted_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == int(result[0][j]):\n",
    "                predicted_word = predicted_word+' '+word\n",
    "                break\n",
    "    res.append(predicted_word)\n",
    "    print(res)\n",
    "    \n",
    "    #for i in res:\n",
    "    #    print(i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "appointed-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_text(model_disc, seed_text):\n",
    "    #print(seed_text)\n",
    "    sequences, tokenizer=tokenizer_data(seed_text)\n",
    "    sequences= pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "    y = model_disc.predict(sequences)\n",
    "    #print(y)\n",
    "    #for i in y:\n",
    "    if(i<0.7):\n",
    "        print(\"fake\")\n",
    "    else:\n",
    "        print(\"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "creative-cartridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 57)\n",
      "(22,)\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 57) for input Tensor(\"input_203:0\", shape=(None, 57), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:544 call\n        result.set_shape(self.compute_output_shape(inputs.shape))\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:534 compute_output_shape\n        output_shape += self._fix_unknown_dimension(input_shape[1:],\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:523 _fix_unknown_dimension\n        raise ValueError(msg)\n\n    ValueError: total size of new array must be unchanged, input_shape = [1, 50], output_shape = [57, 50]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-5830bf84b1c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0md_loss1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_acc_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_real\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# generate 'fake' examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m57\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;31m# update discriminator model weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0md_loss2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_acc_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-169-ab42883d74e2>\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[1;34m(generator, latent_dim, n_samples)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# predict outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m# create class labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:544 call\n        result.set_shape(self.compute_output_shape(inputs.shape))\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:534 compute_output_shape\n        output_shape += self._fix_unknown_dimension(input_shape[1:],\n    C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:523 _fix_unknown_dimension\n        raise ValueError(msg)\n\n    ValueError: total size of new array must be unchanged, input_shape = [1, 50], output_shape = [57, 50]\n"
     ]
    }
   ],
   "source": [
    "# Store the losses\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "sample_period = 100 # every `sample_period` steps generate and save some data\"\n",
    "Epoch=1000\n",
    "#x_real= generate_real_samples()\n",
    "######################## Main training loop###########################\n",
    "for i in range(Epoch):\n",
    "        ########################\n",
    "        ###Train Discriminator##\n",
    "        #######################\n",
    "        # prepare real samples\n",
    "        #x_real= generate_real_samples()\n",
    "        #print(x_real.shape)\n",
    "        #print(x_real[-1])\n",
    "        #noise_real=random.randn(1,57)\n",
    "        #print(x_real.shape)\n",
    "        #print(y_real.shape)\n",
    "        #d_loss_real, d_acc_real=discriminator.train_on_batch(x_real, y_real)\n",
    "        # Generate fake tweets\n",
    "        #noise=random.randn(57,1)\n",
    "        #x_fake= generator.predict([noise,x_real[-1]])\n",
    "        #d_loss_fake, d_acc_fake =discriminator.train_on_batch([noise,x_fake[-1]], y_fake)\n",
    "        #print(\"x_fake shape\",x_fake.shape)\n",
    "        # get randomly selected 'real' samples\n",
    "        [X_real, labels_real], y_real = generate_real_samples(57)\n",
    "        # update discriminator model weights\n",
    "        d_loss1, d_acc_real = discriminator.train_on_batch([X_real, labels_real], y_real)\n",
    "        # generate 'fake' examples\n",
    "        [X_fake, labels], y_fake = generate_fake_samples(generator, 57, 22)\n",
    "        # update discriminator model weights\n",
    "        d_loss2, d_acc_fake = discriminator.train_on_batch([X_fake, labels], y_fake)\n",
    "        # prepare points in latent space as input for the generator\n",
    "        [z_input, labels_input] = generate_latent_points(57, 22)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = ones((33, 1))\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss = gan.train_on_batch([z_input, labels_input], y_gan)\n",
    "        # Train the discriminator\n",
    "        # both loss and accuracy are returned\n",
    "        \n",
    "        d_loss = 0.5 * (d_loss1 + d_loss2)\n",
    "        d_acc  = 0.5 * (d_acc_real + d_acc_fake)\n",
    "        \n",
    "        #######################\n",
    "        ### Train generator ###\n",
    "        #######################\n",
    "    \n",
    "        #y_gan = ones((57, 1))\n",
    "        #print(x_real[-1].shape)\n",
    "        # update the generator via the discriminator's error\n",
    "        #noise=random.randn(57,1)\n",
    "        #gan_model([noise,x_real[-1]], y_gan).summary()\n",
    "        #g_loss, n=gan_model.train_on_batch([noise,x_real[-1]], y_gan)\n",
    "        \n",
    "        # Save the losses\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "        # evaluate discriminator on real examples\n",
    "        #acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
    "        # evaluate discriminator on fake examples\n",
    "        #acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "        \n",
    "        #if i % 2 == 100:#after 100 epoch we save\n",
    "        #if i % sample_period == 0:\n",
    "        #print(f\"epoch: {i+1}, d_loss: {d_loss:.2f}, \\\n",
    "        #d_acc: {d_acc:.2f}, g_loss: {g_loss:.2f}\")\n",
    "        #noiseg=random.randn(1,57)\n",
    "        #sample_tweet(i,noiseg, generator)\n",
    "        #disc_text(discriminator, tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-shelter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-button",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
